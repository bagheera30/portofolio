# -*- coding: utf-8 -*-
"""tugas data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RVQn7wzy5SnkbbPTA3F4S3ngSJW0RRMN

Reading Text Data

Muhammad Rizki Alfian 

1302210112
"""

from google.colab import drive
drive.mount('/content/drive')

raw_data=open('/content/drive/MyDrive/Colab_Notebooks/SMSSpamCollection').read()
 raw_data[0:500]

parsed_data=raw_data.replace('\t','\n').split('\n')
parsed_data[0:10]

label_list=parsed_data[0::2]
msg_list=parsed_data[1::2]
print(label_list[0:5])
print(msg_list[0:5])

import pandas as pd
print(len(label_list))
print(len(msg_list))
print(label_list[-3:])
combined_df=pd.DataFrame({
    'label':label_list[:-1],  
    'sms':msg_list
})

combined_df.head()

"""# **method 2**"""

dataset=pd.read_csv('/content/drive/MyDrive/Colab_Notebooks/SMSSpamCollection',sep="\t",header=None)
dataset.head()

"""# Tokenize"""

import nltk
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
nltk.word_tokenize("hi how are u")

#using split
s='how are you'
s.split(' ')

"""# **removing stopwords**


"""

from nltk.corpus import stopwords
stop_words=stopwords.words('english')
print(stop_words)

#add or remove stopwords
stop_words.append('work')

print(stop_words)